{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualizations of main optimization results\n",
    "\n",
    "This notebook has been created to visualize the comparisons between the optimizations of the differently created models in the in silico study of the paper.\n",
    "\n",
    "We compare here all the models run with 3 labels, but different original sets of parameters. Mainly, we reproduce Figure 4b and Figure 5b, 5c of the paper. But it can also be used to generally explore the dataset."
   ]
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing al necessary functions\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from analyze_results import CumulativeResults\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# We define some variables that will reoccur more often.\n",
    "model_name = 'lipidomics_2023_08_30'\n",
    "res_dict = '../Results_h5'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We start by loading all results of all different models into a singular object, that can then visualize comparisons etc"
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# This function will load each individual hdf5 file. One file represents an optimization of a specific model.\n",
    "cum_res = CumulativeResults(\n",
    "    model_name, res_dict, n_res=1000\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# In addition to the hdf5 file we will be in need of the PEtab problem and the pyPESTO problem accordingly\n",
    "cum_res.load_petab_problems(\"../Petab_models_230829/3_labels\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "cum_res.load_pypesto_problems(force_compile=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We first investigate some general information about the Results:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "non_existing = []\n",
    "for index in range(cum_res.n_results):\n",
    "    if not os.path.isfile(\n",
    "            f\"{res_dict}/{cum_res.model_name}_{index}_{cum_res.n_starts}starts.hdf5\"\n",
    "    ):\n",
    "        non_existing.append(index)\n",
    "cum_res.non_existing = non_existing"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "cum_res.overview_failed_starts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# We want to compare how the optimization of the different models went. This is generally helpfull, as we expect a certain spread in the optimization, i.e. we should be suspicious if all models are fit perfectly or identical.\n",
    "fvals = [result.optimize_result.fval[0] for result in cum_res.results]\n",
    "\n",
    "ax = sns.histplot(fvals, kde=True)\n",
    "plt.xlabel(\"Objective function value\")\n",
    "plt.ylabel(\"Relative frequency\")\n",
    "plt.title(\"Distribution of best objective function values\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.savefig(\"Figure3/fval_dist.pdf\")\n",
    "\n",
    "# compare to standard normal distribution\n",
    "ks_result = stats.normaltest(fvals)\n",
    "print(ks_result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here create the first part of Figure 4B: The cells ranked by objective function value.\n",
    "\n",
    "It is similar to the visualization above, but shows clearer, which is the best median and worst fit. We want to have a deeper investigation to these three models to get a representative overview of the results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fvals = np.array(fvals)\n",
    "fvals_sorted = np.sort(cum_res.fvals_best)\n",
    "fvals_sorted_or = copy.deepcopy(fvals_sorted)\n",
    "indices2plot = np.arange(len(fvals_sorted))\n",
    "sorted_indices = np.round(np.argsort(cum_res.fvals_best)).astype(int)\n",
    "figuresize = (5,1)\n",
    "plot_points = True\n",
    "n_points = 3\n",
    "color_points = [\n",
    "    \"#007f5f\", \"#aacc00\", \"#fca311\", \"#17c3b2\"\n",
    "]\n",
    "figure = plt.figure(figsize=figuresize)\n",
    "indices = np.round(\n",
    "    np.linspace(0, len(fvals_sorted) - 1, n_points).astype(int)\n",
    ")\n",
    "fvals_sorted = np.concatenate((fvals_sorted[0:6:2], fvals_sorted[12:-12:24], fvals_sorted[-6::2]))\n",
    "indices2plot = np.concatenate((indices2plot[0:6:2], indices2plot[12:-12:24], indices2plot[-6::2]))\n",
    "# plot the objective values as points\n",
    "plt.plot(indices2plot, fvals_sorted, 'o', linewidth=2, markersize = 3, color = \"#3B75AF\")\n",
    "plt.xlabel('Cell rank')\n",
    "plt.ylabel('Objective value')\n",
    "\n",
    "if plot_points:\n",
    "    for i in range(n_points):\n",
    "        plt.plot(\n",
    "            indices[i], fvals_sorted_or[indices[i]], 'o',\n",
    "            color=color_points[i], label=f\"Cell {indices[i]}\", markersize = 9\n",
    "        )\n",
    "plt.savefig(\"Model_230830/rank_cells.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Accordingly we want for each of the three fits see what the actual fit looks like. For this, we picked out two lipid classes DAG and LPE to see their exact fit. This corresponds to the middle building block of **Figure 4B**.\n",
    "\n",
    "You can visualize other lipid classes by defining them through (e.g. adding PS as visualization)\n",
    "1. Their base name (e.g. \"PS\")\n",
    "2. The number of fatty acids they will have (e.g. 2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "plt.rcParams[\"lines.linewidth\"] = 3\n",
    "for cell_index in [358, 214, 532]:\n",
    "    for obs_name, obs_level in zip([\"DAG\", \"LPE\"], [2, 1]):  # Here you can place your lipid class of interest\n",
    "        ax = cum_res.plot_time_trajectories_fit(\n",
    "            cell_index = cell_index,\n",
    "            obs_name = obs_name,\n",
    "            obs_labels = obs_level\n",
    "        )\n",
    "        y = ax.get_ylim()\n",
    "        ax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax = y[1]))\n",
    "        ax.get_legend().remove()\n",
    "        ax.set_title(f\"Cell {cell_index}, {obs_name}\")\n",
    "        ax.grid(False)\n",
    "        ax.figure.set_size_inches(5, 5)\n",
    "        ax.set_yticks([0 * y[1], 0.2 * y[1], 0.4 * y[1], 0.6 * y[1], 0.8 * y[1]])\n",
    "        plt.tick_params(left = False, bottom = False, which='both')\n",
    "        # make layout tight\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"Model_230830/10_25_fit_cell_{cell_index}_{obs_name}.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The following block does the same thing, but generates the legend used in **Figure 4B** for us."
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "plt.rcParams[\"lines.markersize\"] = 15\n",
    "plt.rcParams[\"lines.marker\"] = \"\"\n",
    "ax = cum_res.plot_time_trajectories_fit(\n",
    "    cell_index = 358,\n",
    "    obs_name = \"LPE\",\n",
    "    obs_labels = 1\n",
    ")\n",
    "# remove legend\n",
    "ax.get_legend().remove()\n",
    "# add legend manually\n",
    "label_colors = [\n",
    "    \"black\",\n",
    "    \"black\",\n",
    "    \"black\",\n",
    "    (0.502, 0.733, 0.509),\n",
    "    (0.944, 0.730, 0.418),\n",
    "    (0.944, 0.558, 0.744)\n",
    "]\n",
    "labels = [\n",
    "    \"Measurement\",\n",
    "    \"Fitted\",\n",
    "    \"True\",\n",
    "    \"Label 1\",\n",
    "    \"Label 2\",\n",
    "    \"Label 3\"\n",
    "]\n",
    "linestyles = [\n",
    "    \"None\",\n",
    "    \"-\",\n",
    "    \"--\",\n",
    "    \"-\",\n",
    "    \"-\",\n",
    "    \"-\"\n",
    "]\n",
    "markers = [\"o\", \"\", \"\", \"\", \"\", \"\"]\n",
    "handles = [\n",
    "    mlines.Line2D([], [], color=color, linestyle=linestyle, label=label, marker=marker, markersize=8)\n",
    "    for color, linestyle, label, marker in zip(label_colors, linestyles, labels, markers)\n",
    "]\n",
    "# remove grid\n",
    "ax.grid(False)\n",
    "\n",
    "ax.legend(handles=handles, loc='center left',\n",
    "          bbox_to_anchor=(1, 0.5))\n",
    "# set the legend box color to black\n",
    "ax.legend_.get_frame().set_edgecolor('black')\n",
    "# tight layout\n",
    "plt.tight_layout()\n",
    "# save figure\n",
    "plt.savefig(\"Model_230830/fit_cell_358_LPE_legend.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since it will not be possible to give a general overview of all fits of all lipid classes, we also want a scatter plot of all measurements. This will be the third square in the middle building block of **Figure 4B**"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def scatter_plot_single_cell_fit(\n",
    "    cum_result,\n",
    "    cell_index\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the fit of a single cell as a scatter plot.\n",
    "\n",
    "    :param cum_result: The cumulative result object\n",
    "    :param cell_index: The index of the cell to plot.\n",
    "    :return: A matplotlib axis object\n",
    "    \"\"\"\n",
    "    # get the result object\n",
    "    result = cum_result.results[cell_index]\n",
    "    # get the petab problem\n",
    "    petab_problem = cum_result.petab_problems[cell_index]\n",
    "    # get the objective\n",
    "    objective = cum_result.pypesto_problem.objective\n",
    "    # call the objective function with estimated parameters\n",
    "    rdatas_est = objective(\n",
    "        result.optimize_result[0].x,\n",
    "        return_dict=True,\n",
    "    )\n",
    "    # call the objective function with true parameters\n",
    "    rdatas_true = objective(\n",
    "        petab_problem.x_nominal_free_scaled,\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "    return (rdatas_est, rdatas_true)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "color_cells = [\"#007f5f\", \"#aacc00\", \"#fca311\", \"#17c3b2\"]\n",
    "for i_cell, cell_index in enumerate([358, 214, 532]):\n",
    "    if i_cell < 2:\n",
    "        continue\n",
    "    rdatas_est, rdatas_true = scatter_plot_single_cell_fit(\n",
    "        cum_res,\n",
    "        cell_index = cell_index\n",
    "    )\n",
    "    figure = plt.figure()\n",
    "    plt.scatter(\n",
    "        rdatas_true[\"rdatas\"][0].y,\n",
    "        rdatas_est[\"rdatas\"][0].y,\n",
    "        color = color_cells[i_cell],\n",
    "    )\n",
    "\n",
    "    plt.tick_params(left = False, bottom = False, which='both')\n",
    "    # change to log scale\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title('')\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('')\n",
    "    plt.title(f\"Cell {cell_index}\")\n",
    "    figure.set_size_inches(5, 5)\n",
    "    figure.axes[0].grid(False)\n",
    "    plt.savefig(f\"Model_230830/scatter_cell_{cell_index}.pdf\")\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Last but not least, we want to compae whether there is any significant difference in the optimization of a model. For this we visualize the 1000 final optimization values of each local optimization start in a **Waterfall Plot**. In red we will see the overall best found value and the more red points we have the more often this exact likelihood value was found. This represents the right part of **Figure 4B**\n",
    "\n",
    "**However**, while all these together give you a good overview of the model fit and whether the optimization process is able to recover the dynamics reliably, it does not tell us anything about the identifiability of the model, i.e. whether the parameters have been recovered equally well. For this we have created **Figure 5**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "plt.rcParams['axes.edgecolor']='black'\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.Set1.colors)\n",
    "for cell_index in [358, 214, 532]:\n",
    "    ax = cum_res.plot_waterfall(cell_index = cell_index)\n",
    "    print(\n",
    "        cum_res.results[cell_index].optimize_result.fval[0]\n",
    "    )\n",
    "    ax.grid(False)\n",
    "    ax.figure.set_size_inches(4.5, 3)\n",
    "    plt.savefig(f\"Model_230830/waterfall_cell_{cell_index}.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The true parameters have been saved in the PEtab models, which is why we loaded them in the beginning. We make two arrays now, the best found parameter and the true parameters. We want to compare them\n",
    "1. As a scatterplot (**Figure 5B**)\n",
    "2. In terms of distribution (**Figure 5C**)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "cell_indices = len(cum_res.petab_problems)\n",
    "\n",
    "par_est = [\n",
    "    result.optimize_result[0].x for result in cum_res.results\n",
    "]\n",
    "par_true = [\n",
    "    petab_problem.x_nominal_free_scaled for petab_problem in cum_res.petab_problems\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# turn them into arrays\n",
    "par_est = np.array(par_est)\n",
    "par_true = np.array(par_true)\n",
    "# print their shapes\n",
    "print(par_est.shape)\n",
    "print(par_true.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We first run the scatter plot. We turn it down to the first 5 parameters (line 1-3 in the following block) but one can easily extend this. For a given index i (line 5 in the second block), we plot this parameter as a scatterplot. We compare the optimal line (black) against the actual values (x-axis = true, y-axis = estimated values). This should reveal any bias we might encounter. As we can see, some parameters fit very well, while other are completely randomized. Since these are all the best found parameter values and their fit is still good, this points towards a practical unidentifiability of this parameter.\n",
    "\n",
    "The following two block with i=0,1,2,3 reproduce **Figure 5B**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "cum_res.pypesto_problem.x_names[0:5]\n",
    "par_est_few = par_est[:, 0:5]\n",
    "par_true_few = par_true[:, 0:5]\n",
    "\n",
    "cum_res.pypesto_problem.x_names[1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "plt.rcParams['axes.edgecolor']='black'\n",
    "plt.rcParams[\"lines.markersize\"] = 5\n",
    "# plot the scatter plot colored by second dimension\n",
    "i=1\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.scatter(\n",
    "    par_true_few[:, i],\n",
    "    par_est_few[:, i],\n",
    "    label = f\"{cum_res.pypesto_problem.x_names[i]}\",\n",
    "    alpha = 1,\n",
    "    color = \"#3B75AF\",\n",
    ")\n",
    "# get the minimum and maximum value of the true parameters\n",
    "min_true, min_est = np.min(par_true_few[:, i]), np.min(par_est_few[:, i])\n",
    "max_true, max_est = np.max(par_true_few[:, i]), np.max(par_est_few[:, i])\n",
    "min_val = min(min_true, min_est)\n",
    "max_val = max(max_true, max_est)\n",
    "# add a line that goes through (min_val, min_val) and (max_val, max_val)\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color=\"black\")\n",
    "# set x axis limits to -2 and -1\n",
    "plt.xlim(min_val, max_val)\n",
    "plt.xlim(min_true, max_true)  # only for unidentifiable\n",
    "plt.ylim(min_val, max_val)\n",
    "# remove grid\n",
    "plt.grid(False)\n",
    "# # remove tick labels\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# add title\n",
    "plt.title(cum_res.pypesto_problem.x_names[i])\n",
    "# # add a legend\n",
    "# plt.legend(loc='center left',\n",
    "#           bbox_to_anchor=(1, 0.5))\n",
    "plt.tick_params(left = False, bottom = False, which='both')\n",
    "# tight layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Model_230830/scatter_plot_{cum_res.pypesto_problem.x_names[i]}.pdf\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# calculate R^2\n",
    "r_2 = np.corrcoef(par_true_few[:, i], par_est_few[:, i]) ** 2\n",
    "print(f\"Correlation Coefficient: {r_2}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The previous section compared the parameters in a 1:1 setting. We might also be interested how well the general distribution of the parameters compare. For this we create **Figure 5C**"
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "plt.rcParams['axes.edgecolor']='black'\n",
    "plt.rcParams[\"lines.linewidth\"] = 10\n",
    "matplotlib.rc('xtick', labelsize=10)\n",
    "matplotlib.rc('ytick', labelsize=10)\n",
    "ax = cum_res.box_plot_parameters()\n",
    "ax.patch.set_edgecolor('black')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.tick_params(left = False, bottom = False, which='both')\n",
    "plt.grid(False)\n",
    "plt.savefig(f\"Model_230830/boxplots_half_wo_legend.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
